{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b394200-1a06-4b12-a418-404b7a018fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#pip install numpy==1.21\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa466bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import TrainingArguments\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb4d873-cd99-4625-a06f-d0a921b528fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir('new_dataset/'):\n",
    "    if filename.endswith(\"(smallchunks).csv\"):\n",
    "        data.append(filename)\n",
    "dfs = []\n",
    "for i in data:\n",
    "  df = pd.read_csv(f'new_dataset/{i}', engine='python', encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "  df_list = df.iloc[:, 0].tolist()\n",
    "  for i in df_list:\n",
    "    dfs.append(i)\n",
    "res_df = pd.DataFrame(dfs)\n",
    "res_df = res_df.rename(columns={0: 'texts'})\n",
    "res_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db57766-3cf8-44ae-a9fe-2c14470a50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_train, prompts_test = train_test_split(res_df, test_size=0.1)\n",
    "\n",
    "prompts_train = pd.DataFrame(prompts_train)\n",
    "prompts_test = pd.DataFrame(prompts_test)\n",
    "prompts_train.to_csv(\"train_mini1.csv\", index=False, header=False)\n",
    "prompts_test.to_csv(\"test_mini1.csv\", index=False, header=False)\n",
    "\n",
    "train_df = pd.read_csv('train_mini1.csv')\n",
    "test_df = pd.read_csv('test_mini1.csv')\n",
    "\n",
    "train_df.columns = ['texts']\n",
    "test_df.columns = ['texts']\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df, split=\"train\")\n",
    "test_ds = Dataset.from_pandas(test_df, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1294af-88ae-43d4-905d-eb1ed512e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"test\": test_ds\n",
    "})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"texts\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# tokenize training and validation datasets\n",
    "tokenized_data = dataset.map(tokenize_function, batched=True)\n",
    "#tokenized_data = dataset.map(create_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43a0b8-6051-47f8-a033-25e5fc71d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389b91d5-ff4a-4c5a-8b32-deef430f04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41fa6ae-3863-4adb-8016-631817e323d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc77a2-d749-43ea-afaf-62f0673f90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = generate_response('### Instruction:\\nImagine you are a famous writer. Use the provided input to create a piece of fictional text that would be as nice as original text.### Input:\\nHarry Potter meets a spider.\\n\\n### Original text:', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67695a01-e9e1-4776-a45f-f179cba61f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "before.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd21cd-ec6e-4384-82db-9c7ff879e619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be671880-4a7a-4919-8ef5-e8046e74c604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6a6c3-5301-4967-b4ed-04941d29f591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96dd210e-4106-4b9c-9343-dd0b86ead890",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    r=25,\n",
    "    bias=\"none\",\n",
    "    task_type=\"TEXT_GENERATION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0c4b24-283f-4dfd-b79f-4e984d0cef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573176b-7a7a-4938-9bb4-faf83d03db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "  output_dir = \"mistral_fiction_generation4\",\n",
    "  num_train_epochs=6,\n",
    "  #max_steps = 100, # comment out this line if you want to train in epochs\n",
    "  per_device_train_batch_size = 4,\n",
    "  warmup_steps = 0,\n",
    "  logging_steps=10,\n",
    "  save_strategy=\"epoch\",\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  #evaluation_strategy=\"steps\",\n",
    "  #eval_steps=20, # comment out this line if you want to evaluate at the end of each epoch\n",
    "  learning_rate=2e-4,\n",
    "  bf16=True,\n",
    "  lr_scheduler_type='constant_with_warmup',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d9bf564-d97a-47fa-8083-222c4fe84d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sample):\n",
    "  bos_token = \"<s>\"\n",
    "  original_system_message = \"You are a famous writer and you are writing a book.\\n\\nYou must write only the plot of THIS CHAPTER and nothing else: \\n SETTING:\"\n",
    "  system_message = \"Imagine you are a famous writer. Use the provided input to create a piece of fictional text that would be as nice as original text.\"\n",
    "  #response = sample[\"texts\"].replace(original_system_message, \"\").replace(\"\\n\\n### Instruction\\n\", \"\").replace(\"\\n### Response\\n\", \"\").strip()\n",
    "  response = re.search(r'(?<=\\[\\/INST\\]).*', sample[\"texts\"], re.DOTALL).group().strip() if re.search(r'(?<=\\[\\/INST\\]).*', sample[\"texts\"], re.DOTALL) else None\n",
    "  input = re.search(r'(?<=\\[INST\\]).*(?=\\[\\/INST\\])', sample[\"texts\"], re.DOTALL).group().strip() if re.search(r'(?<=\\[INST\\]).*(?=\\[\\/INST\\])', sample[\"texts\"], re.DOTALL) else None\n",
    "  eos_token = \"</s>\"\n",
    "\n",
    "  full_prompt = \"\"\n",
    "  full_prompt += bos_token\n",
    "  full_prompt += \"### Instruction:\"\n",
    "  full_prompt += \"\\n\" + system_message\n",
    "  full_prompt += \"\\n\\n### Input:\"\n",
    "  full_prompt += \"\\n\" + input\n",
    "  full_prompt += \"\\n\\n### Original text:\"\n",
    "  full_prompt += \"\\n\" + response\n",
    "  full_prompt += eos_token\n",
    "\n",
    "  to_delete = \"You are a famous writer and you are writing a book.\\n\\nYou must write only the plot of THIS CHAPTER and nothing else: \\n SETTING:\"\n",
    "  full_prompt = full_prompt.replace(to_delete, \"\")\n",
    "\n",
    "  return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce72b4-cb28-45cf-8203-e3aa497e462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row_prompt = create_prompt(prompts_train.iloc[0])\n",
    "print(first_row_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d786ea-70e9-4c1b-87c8-776dd13b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 2048\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "  model=model,\n",
    "  peft_config=peft_config,\n",
    "  max_seq_length=max_seq_length,\n",
    "  tokenizer=tokenizer,\n",
    "  packing=False,\n",
    "  formatting_func=create_prompt,\n",
    "  args=args,\n",
    "  train_dataset=tokenized_data[\"train\"],\n",
    "  eval_dataset=tokenized_data[\"test\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b2ca6-c956-4e2e-aebd-27d3971c6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff3495-1583-4e89-8840-a9067186cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = training_args.max_train_samples if training_args.max_train_samples is not None else len(train_dataset)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39937c-1640-484a-90dd-c8cc60430b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "018e532b-d46f-4d26-8a05-07b851283775",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"mistral_fiction4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7a2e6-3f9e-43e9-a8fb-c0a0cd66eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2a8f1177-6670-4db6-8b46-91e3ee5be6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "52ea6174-017f-4da2-9749-cc6ddde75ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction:\\nImagine you are a famous writer. Use the provided input to create a piece of fictional text that would be as nice as original text.### Input:\\nHarry Potter meets a spider.\\n\\n### Original text: \\nHarry Potter sits down in the Gryffindor common room. After a while, he observes a spider crawling along the ceiling. He knows he isn\\'t supposed to disturb it but he can\\'t help it. He whispers to the spider, \"You\\'ll have to forgive me, but spiders give me the creeps.\" The spider doesn\\'t seem to notice him and continues to crawl along the ceiling. Harry lets out a sigh and stands up, \"This is ridiculous.\" He turns to his friends, \"Guys, can you get a broom or something and get rid of that spider?\" The spider then drops from the ceiling and falls on Harry\\'s head.         \\n### Fictional text:\\nHarry Potter spent his time in the Gryffindor common room. After a while, he watched a spider crawl along the ceiling. Harry knew it was one of the unbreakable rules in his education that spiders were not to be tampered with. Despite the knowledge, his discomfort started to seep in as the spider kept making its way along the ceiling. Harry whispered to the spider, \"I\\'m sorry, but spiders give me the heebie-jeebies.\" The spider paid no attention to Harry and kept moving forward. Harry stood up and shook his head, \"This is getting ridiculous.\" He looked over to his friends and asked for their help to remove the spider. The spider dropped from the ceiling, onto Harry\\'s head. Harry groaned in surprise as the spider crawled onto his head.          Harry stood quickly, trying to shake off the spider, but it clung to his head. Harry looked around nervously and asked for his friends\\' help before running into the dormitory room. The spider continued to move around on his head until Harry finally found comfort in the arms of his friends. The spider slowly made its way off Harry\\'s head and crawled back onto the ceiling.          Harry returned to his seat and quietly enjoyed the company of his friends as they watched the spider continue its journey along the ceiling. Harry knew that this wouldn\\'t be the only encounter he would have with spiders and was relieved that he would soon be able to see the day when he would be able to overcome his fear of them.          As time went on, Harry became more confident in his abilities to handle spiders. He even started to hunt them for fun. Though he was never quite sure why, he found that killing the spiders gave him a sense of satisfaction and a sense of power. His adventures around the castle gave him a good opportunity to have this experience.          After a particularly close encounter with a big red spider, Harry decided he had had enough adventure for the day. He put on his robe and wand, and began his journey back to the dormitory.          As he was walking back to his room, he was approached by a small, grey spider crawling toward him. Harry knew he was making it too easy, and that the spider might be too fast for him. As he bent to pick up his wand, the spider crawled onto his helmet.          Harry groaned, trying to shake off the spider, but realized too late that his helmet was too small for his helmet. He pulled it off his head and looked around for his wand. But there it was, right in front of him, clinging to the spider.          Harry stepped back quickly, avoiding the spider\\'s web, as he watched his friends take notice of his new companion. They cheered and cheered as they watched Harry dance around with the spider on his helmet.          Harry was having a great time when he suddenly realized he needed to find his wand. Quickly, he reached out for it and picked it up. As he stood there, he saw a flash of movement out of the corner of his eye.          The spider had just landed on Harry\\'s back and was starting to crawl down. Harry quickly turned to see the spider, but he was too late. The spider crawled down the chest of Harry\\'s robe and disappeared from view. Harry sighed deeply and took off his helmet, feeling relieved to be rid of the spider.          As he walked back to his room, he couldn\\'t help but imagine all the trouble there would be when he had to face the spider again.          Harry sighed to himself as he entered his room and closed the door behind him. He was exhausted from his encounter with the spider and closed his eyes to rest. But his mind was not at peace. Harry knew he had to face his spider again.          In that moment, Harry realized that he had conquered his fear of sp'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"### Instruction:\\nImagine you are a famous writer. Use the provided input to create a piece of fictional text that would be as nice as original text.### Input:\\nHarry Potter meets a spider.\\n\\n### Original text:\", merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ae52d-da82-46fb-8a47-48b1bce6252e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
